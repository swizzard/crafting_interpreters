* I had some uncertainty about error handling. The way Rust does errors is one of my favorite things about it, but I was a little unsure how far to let `Err`s bubble up, especially given the way Nystrom's Java implementation does it (a mutable `hasError` attribute in the scanner class.) I think I handled it ok, but reserve the right to go back and change things.
* Nystrom makes `Token` a class with an enum `TokenType` field. I just made it a regular Rust `enum`.
    * The only place this kind of bit me was in [`scanner::ident_t`](../main/src/scanner.rs#L199). Nystrom handles it with a `Map`; since Rust (afaik) doesn't allow partial application of variants[^1], I had to do yet another big `match` statement.
* I also ran into a bit of an unfortunate situation in [`scanner::scan_token`](../main/src/scanner.rs#L69) handling comments and whitespace. Nystrom has an `addToken` method that appends to a mutable list of tokens stored in the scanner class. I decided to go Rustier and iterate + match. The upside to this was that it's more idiomatic and I didn't need all the helper methods he has to manage the index etc. The problem is that, unlike Nystrom, I can't just throw away whitespace and comments, because
  there's otherwise no way to distinguish between "stuff we don't care about" and `eof`. It's not a big hurdle, I'll just have to be sure to filter out `Token::Whitespace` and `Token::Comment` when it's time to build the AST.
* I'm not sure (yet) what the point of having both `lexeme` and `literal` is. Maybe it'll become clearer in later chapters. 
* Once again, Rust's testing story absolutely whips ass. Being able to return an error type from a test is so beautiful, even though you have to add `Ok(())` at the end of every test. If I knew more lua/vimscript, I'd write a macro or whatever that would scaffold `#[test]\nOk(())` for you.
  * The tests are pretty trivial for now, but already caught a few bugs, including 2 places where I'd forgotten to advance the iterator, leading to an endless loop.
* I had initially wanted to do this without any external libraries. If I weren't doing this for my own edification, I'd obviously reach for [nom](https://docs.rs/nom/latest/nom/), but figured (correctly) that doing the parsing by hand would be a satisfying experience.
  * I ended up going with [thiserror](https://docs.rs/thiserror/latest/thiserror/), even though to be perfectly honest [anyhow](https://docs.rs/anyhow/latest/anyhow/) would probably be fine for something this scale. 
  * [rustyline](https://crates.io/crates/rustyline) gave me a few nice things that I think bring Rust's built-in readline stuff up to par with Java's.
  * [peekmore](https://docs.rs/peekmore/latest/peekmore/) addresses [one very specific need](../main/src/scanner.rs#L159)--checking if the character after the `.` when parsing a number is a digit or not. I maybe could've tried to do it with just [Peekable](https://doc.rust-lang.org/stable/std/iter/struct.Peekable.html) but peeking->advancing->peeking->putting stuff back on top of the iterator could've gotten messy quickly, and I'd already pulled in other crates so who cares.


[^1]: e.g.
    ```rust
      lazy_static! {
        static ref RESERVED_WORDS: HashMap<String, Token> = ...
      }
      fn ident_maker(s: String, line: usize, t: Option<Token>) -> Token {
        if let Some(t) = RESERVED_WORDS.get(s) {
          t { line, literal: s.clone(), lexeme: s }
        } else {
          Token::Identifier { line, literal: s.clone(), lexeme: s }
        }
      }
    ```
